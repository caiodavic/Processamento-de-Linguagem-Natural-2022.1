{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6EXhSTuPuAp0jiEZiybal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiodavic/Processamento-de-Linguagem-Natural-2022.1/blob/main/Classifica%C3%A7%C3%A3o_de_Texto_com_Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificação de Sátiras com Word Embedding\n",
        "- Vamos classificar um dataset que contém notícias reais e sátiras utilizando Word Embeddings. Após a classificação, vamos extrair os pesos da primeira camada (Camada de Embedding) da rede neural e criar nossa matriz de Embeddings. "
      ],
      "metadata": {
        "id": "RAgFfzWXoUYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando as Bibliotecas necessárias"
      ],
      "metadata": {
        "id": "Z81ZT8Ido-FY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2NfcxhJoN2m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# com essa célula o google colab consegue ler arquivos direto do google drive. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGwzQ2WDpezq",
        "outputId": "d3a43806-5e9c-4dca-ddeb-b7ec7f8fd859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leitura de Dados e Divisão dos Dados"
      ],
      "metadata": {
        "id": "NvfNeBifpWRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# é importante alterar o caminho e colocar para onde o arquivo está salvo no seu drive\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/2022.1/PLN/csv_satiras_reais.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1jNqeIY1pUeI",
        "outputId": "f9568cfd-5a6b-4c27-b0a9-a51b3f3b920c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0   crise e tao grande que nem tiozao do pave fez...   \n",
              "1   nao me representam diz jesus sobre intolerant...   \n",
              "2   marina silva e heloisa helena montam novo par...   \n",
              "3   dez propostas que podem realmente mudar o brasil   \n",
              "4   apresentadora do cidade alerta bahia dara cur...   \n",
              "\n",
              "                                                text   label  \n",
              "0  a familia guimaraes passou a noite de natal pe...  satire  \n",
              "1  uma menina de 11 anos apedrejada ao sair de um...  satire  \n",
              "2  insatisfeitas com seus partidos com as siglas ...  satire  \n",
              "3  o instituto nupal nucleo de pesquisas da ameri...  satire  \n",
              "4  assassinatos sequestros mortes violentas.  nen...  satire  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92e8b07f-ebea-4ab8-b998-b69a2bc7ead4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>crise e tao grande que nem tiozao do pave fez...</td>\n",
              "      <td>a familia guimaraes passou a noite de natal pe...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nao me representam diz jesus sobre intolerant...</td>\n",
              "      <td>uma menina de 11 anos apedrejada ao sair de um...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>marina silva e heloisa helena montam novo par...</td>\n",
              "      <td>insatisfeitas com seus partidos com as siglas ...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dez propostas que podem realmente mudar o brasil</td>\n",
              "      <td>o instituto nupal nucleo de pesquisas da ameri...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apresentadora do cidade alerta bahia dara cur...</td>\n",
              "      <td>assassinatos sequestros mortes violentas.  nen...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92e8b07f-ebea-4ab8-b998-b69a2bc7ead4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92e8b07f-ebea-4ab8-b998-b69a2bc7ead4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92e8b07f-ebea-4ab8-b998-b69a2bc7ead4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data['text']\n",
        "y = [1 if i == 'satire' else 0 for i in data['label']]\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)"
      ],
      "metadata": {
        "id": "q6Q4mCLlrpRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos dados"
      ],
      "metadata": {
        "id": "axhAsaM_r0CE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenização, criação do vocabulário e \"padded\"\n",
        "- A fim de transformar nossos dados  para que a primeira camada possa receber, precisamos tokenizar, e fazer com que todos os vetores de sentenças tenham a mesma dimensão.\n"
      ],
      "metadata": {
        "id": "nDvTSGNsr4UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "vocab_size = 10000\n",
        "oov_token = \"<OOV>\"\n",
        "embedding_dim = 64\n",
        "max_length = 120\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_token)"
      ],
      "metadata": {
        "id": "twPB8ycYpbmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Vamos criar nosso tokenizador com os dados da coluna de texto do treinamento "
      ],
      "metadata": {
        "id": "U3d6C5Drsr2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "8vR7mHCjsndf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "id": "9NElPVK8s1qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0fb5ad1-ed2e-4e1a-e57f-99508105f7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62125"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Agora precisamos mapear nossas palavras para o índice que o tokenizador criou."
      ],
      "metadata": {
        "id": "yafHhIO2tUk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_sequences = tokenizer.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "8NtOqzcOq0IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Com as palavras mapeadas para valores, precisamos agora tornar todas as sequências do mesmo tamanho. Temos um tamanho máximo de 100. Vamos utilizar `padding`e `truncating`com o valor 'post', isso significa que tanto para truncar a sentença ou aumentar o seu vetor será feito no final do vetor."
      ],
      "metadata": {
        "id": "wCSH_vV1tfm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_padded = pad_sequences(x_train_sequences, maxlen = max_length, padding = 'post',truncating='post')\n",
        "x_test_padded = pad_sequences(x_test_sequences, maxlen= max_length, padding = 'post',truncating='post')"
      ],
      "metadata": {
        "id": "Qv_wqXlWta7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construindo a Rede Neural\n",
        "- Vamos treinar a rede neural para classificar nossos textos. Uma vez que a rede neural está treinada, podemos extrair os pesos da primeira camada, assim teremos nossos embeddings."
      ],
      "metadata": {
        "id": "6X__uU5KxaqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(64,activation='relu')))\n",
        "model.add(tf.keras.layers.Dense(6,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "uMzZxRrXxaY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9ogY5tMnxriD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "HN_KXwe1xtia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718ed248-99dd-49d8-9587-f252347b8648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 120, 64)           640000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              16512     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 657,293\n",
            "Trainable params: 657,293\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train_padded,np.array(y_train),epochs=10,validation_data=(x_test_padded,np.array(y_test)))"
      ],
      "metadata": {
        "id": "i3kQQ9Nax5H0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70365f4-c582-4acb-83bb-624bd04d2366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 18s 64ms/step - loss: 0.4980 - accuracy: 0.7609 - val_loss: 0.3154 - val_accuracy: 0.8840\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.2600 - accuracy: 0.9087 - val_loss: 0.3159 - val_accuracy: 0.8615\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.1185 - accuracy: 0.9592 - val_loss: 0.1490 - val_accuracy: 0.9475\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 17s 66ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.1545 - val_accuracy: 0.9555\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.1783 - val_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 17s 68ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1595 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 16s 64ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1795 - val_accuracy: 0.9580\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 2.4391e-04 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9555\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 1.2886e-04 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9560\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 6.1373e-05 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test_padded, np.array(y_test))\n",
        "print(f'A acurácia foi de: {accuracy}')"
      ],
      "metadata": {
        "id": "8hWdF7w2yMx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2d487f-c5f0-4720-f77a-97fb6c59b00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 14ms/step - loss: 0.2311 - accuracy: 0.9540\n",
            "A acurácia foi de: 0.9539999961853027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração dos pesos\n",
        "- Extraindo os pesos, podemos exportar o vetor de cada palavra do nosso vocabulário"
      ],
      "metadata": {
        "id": "klWp-EAEGtWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcuHNO3lFNFs",
        "outputId": "9b09366f-ba31-4482-ccee-0d1052f43861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reversed_word_index = {}\n",
        "for i in word_index.keys():\n",
        "  reversed_word_index[word_index[i]] = i\n",
        "\n",
        "reversed_word_index"
      ],
      "metadata": {
        "id": "ICLn6gs_IFnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "out_vectors = io.open('vecs.txt', 'w', encoding='utf-8')\n",
        "out_vectors.write(f'{vocab_size} {embedding_dim}\\n')\n",
        "\n",
        "for word_num in range(1,vocab_size+1):\n",
        "  \n",
        "  word = reversed_word_index[word_num]\n",
        "  embeddings = weights[word_num-1]\n",
        "  line_embedding =  word +' ' + ' '.join([str(x) for x in embeddings])+ '\\n'\n",
        "  if word_num == vocab_size:\n",
        "    line_embedding = line_embedding.rstrip()  \n",
        "  out_vectors.write(line_embedding)\n",
        "  \n",
        "out_vectors.close()"
      ],
      "metadata": {
        "id": "cORekCgh2f6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model_embedding = KeyedVectors.load_word2vec_format('vecs.txt')"
      ],
      "metadata": {
        "id": "HxdzUzu_JGR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_embedding.get_vector('amor')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CZxHCuvJbii",
        "outputId": "d4593762-4ad5-4861-c40e-e80058ebcf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-7.7490255e-02,  2.8578673e-02, -2.9935014e-02,  4.0734537e-02,\n",
              "        3.7374351e-02,  4.3725137e-02, -4.3079942e-02,  2.5085259e-02,\n",
              "       -3.6693448e-03, -7.5272828e-02, -6.2611312e-02,  3.5357263e-02,\n",
              "        4.4600915e-02,  4.1194756e-02,  1.0161753e-01,  7.6673083e-02,\n",
              "        3.5793759e-02,  2.5541573e-05, -3.2469507e-02,  2.0374404e-02,\n",
              "        2.2557979e-02, -7.0923664e-02, -5.7299502e-02,  6.3124470e-02,\n",
              "        1.1048226e-02,  1.0526380e-02,  2.8292488e-02,  2.0341251e-02,\n",
              "        1.6981418e-03, -3.1631985e-03,  8.5497379e-02,  6.4519249e-02,\n",
              "       -3.5611324e-03,  1.4506328e-02,  5.6007400e-02,  4.0687256e-02,\n",
              "       -4.0227380e-02,  8.5500693e-03,  1.8519528e-02, -5.9586897e-02,\n",
              "       -5.5159714e-02,  1.1555127e-02,  1.1547644e-02,  4.0947422e-02,\n",
              "       -5.1473878e-02, -5.0669424e-02, -6.3177362e-02,  5.4570053e-02,\n",
              "       -9.0539356e-04, -4.7544021e-02,  6.8863913e-02,  9.4348982e-02,\n",
              "        5.3891331e-02,  3.5973992e-02, -3.8921371e-02,  4.7982961e-02,\n",
              "        8.2256958e-02,  7.4419202e-03,  2.0891488e-02, -5.4715175e-02,\n",
              "        6.4236656e-02,  7.6450802e-02, -2.7931796e-02,  4.5768026e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_embedding.most_similar(negative=['amor'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vsh9C5Jr1O2",
        "outputId": "c18511d9-003c-444b-9a10-3f22b9f8c5a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('militancia', 0.5878221988677979),\n",
              " ('verao', 0.5773073434829712),\n",
              " ('grandes', 0.5753006935119629),\n",
              " ('saida', 0.5650980472564697),\n",
              " ('excecao', 0.5454781651496887),\n",
              " ('juntou', 0.5452638864517212),\n",
              " ('17', 0.5323375463485718),\n",
              " ('atrair', 0.5282691717147827),\n",
              " ('restricao', 0.5244694948196411),\n",
              " ('apresentador', 0.5198777914047241)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('tensors.tsv', 'w') as tensors:\n",
        "    with open('metadata.tsv', 'w') as metadata:\n",
        "        for word in model_embedding.wv.index2word:\n",
        "            metadata.write(word + '\\n')\n",
        "            vector_row = '\\t'.join(map(str, model_embedding.wv[word]))\n",
        "            tensors.write(vector_row + '\\n')"
      ],
      "metadata": {
        "id": "BfjQq9MavcyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d5adaf-ee94-44a8-8c75-6e54647ce007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-5091996d392d>:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  for word in model_embedding.wv.index2word:\n",
            "<ipython-input-36-5091996d392d>:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  vector_row = '\\t'.join(map(str, model_embedding.wv[word]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('tensors.tsv')\n",
        "  files.download('metadata.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ewd6CXVnyCO6",
        "outputId": "3e253ce5-2068-4996-d4e3-d67a37f94f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ae864a38-a9f6-487a-b7fb-44738302b489\", \"tensors.tsv\", 7834142)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da3afe03-8bf5-4af7-8e30-5678cbf8d277\", \"metadata.tsv\", 84912)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}